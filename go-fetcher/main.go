package main

import (
	"bufio"
	"encoding/json"
	"encoding/xml"
	"fmt"
	"html"
	"io"
	"log"
	"math/rand"
	"net/http"
	"net/url"
	"os"
	"path/filepath"
	"strings"
	"sync"
	"time"
)

// RSS ç»“æ„
type RSS struct {
	Channel struct {
		Items []RSSItem `xml:"item"`
	} `xml:"channel"`
}

type Atom struct {
	Entries []AtomEntry `xml:"entry"`
}

type RSSItem struct {
	Title string `xml:"title"`
	Link  string `xml:"link"`
}

type AtomEntry struct {
	Title string   `xml:"title"`
	Link  AtomLink `xml:"link"`
}

type AtomLink struct {
	Href string `xml:"href,attr"`
}

// å†å²è®°å½•
type HistoryItem struct {
	Title     string `json:"title"`
	URL       string `json:"url"`
	Timestamp string `json:"timestamp"`
}

// æŠ“å–ç»“æœ
type TrendItem struct {
	Title string `json:"title"`
	URL   string `json:"url"`
}

// User-Agent æ± 
var userAgents = []string{
	"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
	"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
	"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0",
	"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
}

// å¤‡ç”¨ RSSHub é•œåƒï¼ˆæŒ‰ç¨³å®šæ€§æ’åºï¼‰
var backupMirrors = []string{
	"https://rsshub.app",
}

var (
	primaryRSSHub   string
	currentMirrorIdx int
	httpClient      *http.Client
)

func init() {
	// åˆå§‹åŒ– HTTP å®¢æˆ·ç«¯ï¼Œå¸¦è¶…æ—¶å’Œè¿æ¥æ± 
	httpClient = &http.Client{
		Timeout: 30 * time.Second,
		Transport: &http.Transport{
			MaxIdleConns:        100,
			MaxIdleConnsPerHost: 10,
			IdleConnTimeout:     90 * time.Second,
		},
	}
	
	// ä»ç¯å¢ƒå˜é‡è·å–ä¸» RSSHub
	primaryRSSHub = os.Getenv("RSSHUB_URL")
	if primaryRSSHub == "" {
		primaryRSSHub = "https://rsshub.app"
	}
	
	rand.Seed(time.Now().UnixNano())
}

func getRandomUA() string {
	return userAgents[rand.Intn(len(userAgents))]
}

func getCurrentRSSHub() string {
	if currentMirrorIdx == 0 {
		return primaryRSSHub
	}
	if currentMirrorIdx <= len(backupMirrors) {
		return backupMirrors[currentMirrorIdx-1]
	}
	return primaryRSSHub
}

func switchToBackup() {
	currentMirrorIdx++
	if currentMirrorIdx > len(backupMirrors) {
		currentMirrorIdx = 0 // å›åˆ°ä¸»å®ä¾‹é‡è¯•
	}
	log.Printf("ğŸ”„ Switching to mirror: %s", getCurrentRSSHub())
}

// é‡ç½®å›ä¸» RSSHub
func resetToPrimary() {
	currentMirrorIdx = 0
	log.Printf("ğŸ”„ Reset to primary RSSHub: %s", primaryRSSHub)
}

// å¸¦é‡è¯•çš„ HTTP è¯·æ±‚
func fetchWithRetry(url string, maxRetries int) ([]byte, error) {
	var lastErr error
	
	for attempt := 0; attempt < maxRetries; attempt++ {
		req, err := http.NewRequest("GET", url, nil)
		if err != nil {
			lastErr = err
			continue
		}
		
		req.Header.Set("User-Agent", getRandomUA())
		req.Header.Set("Accept", "application/xml, text/xml, */*")
		
		resp, err := httpClient.Do(req)
		if err != nil {
			lastErr = err
			log.Printf("âš ï¸ Attempt %d failed for %s: %v", attempt+1, url, err)
			time.Sleep(time.Duration(attempt+1) * 2 * time.Second)
			continue
		}
		
		if resp.StatusCode != 200 {
			resp.Body.Close()
			lastErr = fmt.Errorf("HTTP %d", resp.StatusCode)
			log.Printf("âš ï¸ Attempt %d returned %d for %s", attempt+1, resp.StatusCode, url)
			time.Sleep(time.Duration(attempt+1) * 2 * time.Second)
			continue
		}
		
		body, err := io.ReadAll(resp.Body)
		resp.Body.Close()
		if err != nil {
			lastErr = err
			continue
		}
		
		return body, nil
	}
	
	return nil, fmt.Errorf("all %d attempts failed: %v", maxRetries, lastErr)
}

// è§£æ RSS/Atom
func parseRSS(data []byte) []TrendItem {
	var items []TrendItem
	
	// å°è¯• RSS æ ¼å¼
	var rss RSS
	if err := xml.Unmarshal(data, &rss); err == nil && len(rss.Channel.Items) > 0 {
		for i, item := range rss.Channel.Items {
			if i >= 10 {
				break
			}
			title := html.UnescapeString(strings.TrimSpace(item.Title))
			if title != "" {
				items = append(items, TrendItem{
					Title: title,
					URL:   strings.TrimSpace(item.Link),
				})
			}
		}
		return items
	}
	
	// å°è¯• Atom æ ¼å¼
	var atom Atom
	if err := xml.Unmarshal(data, &atom); err == nil && len(atom.Entries) > 0 {
		for i, entry := range atom.Entries {
			if i >= 10 {
				break
			}
			title := html.UnescapeString(strings.TrimSpace(entry.Title))
			if title != "" {
				items = append(items, TrendItem{
					Title: title,
					URL:   entry.Link.Href,
				})
			}
		}
	}
	
	return items
}

// æŠ“å–å•ä¸ª RSS æº
func fetchSingleRSS(name, rssURL string, useBackup bool) ([]TrendItem, error) {
	// æ›¿æ¢ RSSHub URL
	currentHub := getCurrentRSSHub()
	if strings.Contains(rssURL, "rsshub.app") {
		rssURL = strings.Replace(rssURL, "https://rsshub.app", currentHub, 1)
	}
	
	data, err := fetchWithRetry(rssURL, 3)
	if err != nil {
		// å¦‚æœä¸»å®ä¾‹å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨
		if !useBackup && strings.Contains(rssURL, currentHub) {
			switchToBackup()
			newURL := strings.Replace(rssURL, currentHub, getCurrentRSSHub(), 1)
			return fetchSingleRSS(name, newURL, true)
		}
		return nil, err
	}
	
	items := parseRSS(data)
	if len(items) == 0 {
		return nil, fmt.Errorf("no items parsed")
	}
	
	return items, nil
}

// è¯»å– RSS é…ç½®
func loadRSSConfig(configPath string) (map[string]string, error) {
	file, err := os.Open(configPath)
	if err != nil {
		return nil, err
	}
	defer file.Close()
	
	feeds := make(map[string]string)
	scanner := bufio.NewScanner(file)
	
	for scanner.Scan() {
		line := strings.TrimSpace(scanner.Text())
		if line == "" || strings.HasPrefix(line, "#") {
			continue
		}
		
		parts := strings.Split(line, "|")
		if len(parts) < 3 {
			continue
		}
		
		name := strings.TrimSpace(parts[0])
		url := strings.TrimSpace(parts[1])
		enabled := strings.ToLower(strings.TrimSpace(parts[2]))
		
		if enabled == "true" {
			feeds[name] = url
		}
	}
	
	return feeds, scanner.Err()
}

// è¯»å–å…³é”®è¯
func loadKeywords(configPath string) [][]string {
	file, err := os.Open(configPath)
	if err != nil {
		log.Printf("No keywords file found: %v", err)
		return nil
	}
	defer file.Close()
	
	var keywords [][]string
	scanner := bufio.NewScanner(file)
	
	for scanner.Scan() {
		line := strings.TrimSpace(scanner.Text())
		if line == "" || strings.HasPrefix(line, "#") {
			continue
		}
		words := strings.Fields(line)
		if len(words) > 0 {
			keywords = append(keywords, words)
		}
	}
	
	return keywords
}

// å…³é”®è¯è¿‡æ»¤
func matchKeywords(title string, keywordGroups [][]string) bool {
	if len(keywordGroups) == 0 {
		return true // æ²¡æœ‰å…³é”®è¯é…ç½®ï¼Œè¿”å›æ‰€æœ‰
	}
	
	titleLower := strings.ToLower(title)
	
	for _, group := range keywordGroups {
		matched := false
		excluded := false
		
		for _, word := range group {
			wordLower := strings.ToLower(word)
			
			if strings.HasPrefix(word, "!") {
				// æ’é™¤è¯
				if strings.Contains(titleLower, strings.ToLower(word[1:])) {
					excluded = true
					break
				}
			} else if strings.HasPrefix(word, "+") {
				// å¿…é¡»è¯
				if !strings.Contains(titleLower, strings.ToLower(word[1:])) {
					matched = false
					break
				}
				matched = true
			} else {
				// æ™®é€šè¯ï¼ˆä»»æ„åŒ¹é…ï¼‰
				if strings.Contains(titleLower, wordLower) {
					matched = true
				}
			}
		}
		
		if matched && !excluded {
			return true
		}
	}
	
	return false
}

// è¯»å–å†å²è®°å½•
func loadHistory(historyPath string) map[string]bool {
	history := make(map[string]bool)
	
	data, err := os.ReadFile(historyPath)
	if err != nil {
		return history
	}
	
	var items []HistoryItem
	if err := json.Unmarshal(data, &items); err != nil {
		return history
	}
	
	for _, item := range items {
		history[item.URL] = true
	}
	
	return history
}

// ä¿å­˜å†å²è®°å½•
func saveHistory(historyPath string, newItems []TrendItem, existingHistory map[string]bool) error {
	// è¯»å–ç°æœ‰å†å²
	var items []HistoryItem
	data, err := os.ReadFile(historyPath)
	if err == nil {
		json.Unmarshal(data, &items)
	}
	
	// æ·»åŠ æ–°é¡¹ç›®
	now := time.Now().Format(time.RFC3339)
	for _, item := range newItems {
		if !existingHistory[item.URL] {
			items = append(items, HistoryItem{
				Title:     item.Title,
				URL:       item.URL,
				Timestamp: now,
			})
		}
	}
	
	// åªä¿ç•™æœ€è¿‘ 1000 æ¡
	if len(items) > 1000 {
		items = items[len(items)-1000:]
	}
	
	newData, err := json.MarshalIndent(items, "", "  ")
	if err != nil {
		return err
	}
	
	return os.WriteFile(historyPath, newData, 0644)
}

// å‘é€ Telegram æ¶ˆæ¯
func sendTelegram(token, chatID, message string) error {
	apiURL := fmt.Sprintf("https://api.telegram.org/bot%s/sendMessage", token)
	
	data := url.Values{}
	data.Set("chat_id", chatID)
	data.Set("text", message)
	data.Set("parse_mode", "Markdown")
	data.Set("disable_web_page_preview", "true")
	
	resp, err := http.PostForm(apiURL, data)
	if err != nil {
		return err
	}
	defer resp.Body.Close()
	
	if resp.StatusCode != 200 {
		body, _ := io.ReadAll(resp.Body)
		return fmt.Errorf("telegram error: %s", string(body))
	}
	
	return nil
}

// æ ¼å¼åŒ–æ¶ˆæ¯
func formatMessage(items []TrendItem) string {
	var sb strings.Builder
	
	for i, item := range items {
		// è½¬ä¹‰ Markdown ç‰¹æ®Šå­—ç¬¦
		title := strings.ReplaceAll(item.Title, "[", "\\[")
		title = strings.ReplaceAll(title, "]", "\\]")
		
		sb.WriteString(fmt.Sprintf("%d. [%s](%s)\n\n", i+1, title, item.URL))
	}
	
	return sb.String()
}

// é¢„çƒ­ RSSHubï¼ˆç­‰å¾…å†·å¯åŠ¨ï¼‰
func warmupRSSHub() {
	log.Printf("ğŸ”¥ Warming up RSSHub: %s", primaryRSSHub)
	
	// Railway å…è´¹ç‰ˆå†·å¯åŠ¨å¯èƒ½éœ€è¦ 60 ç§’
	// åˆ›å»ºä¸€ä¸ªä¸“é—¨ç”¨äºé¢„çƒ­çš„å®¢æˆ·ç«¯ï¼Œè¶…æ—¶æ›´é•¿
	warmupClient := &http.Client{
		Timeout: 90 * time.Second,
	}
	
	// å°è¯• 3 æ¬¡é¢„çƒ­
	for attempt := 1; attempt <= 3; attempt++ {
		log.Printf("ğŸ”„ Warmup attempt %d/3...", attempt)
		
		req, _ := http.NewRequest("GET", primaryRSSHub, nil)
		req.Header.Set("User-Agent", getRandomUA())
		
		resp, err := warmupClient.Do(req)
		if err != nil {
			log.Printf("âš ï¸ Warmup attempt %d failed: %v", attempt, err)
			if attempt < 3 {
				time.Sleep(10 * time.Second)
			}
			continue
		}
		resp.Body.Close()
		
		if resp.StatusCode == 200 {
			log.Println("âœ… RSSHub warmup successful!")
			return
		}
		
		log.Printf("âš ï¸ Warmup returned %d", resp.StatusCode)
		if attempt < 3 {
			time.Sleep(10 * time.Second)
		}
	}
	
	log.Printf("âš ï¸ Primary RSSHub warmup failed after 3 attempts, will try backup if needed")
}

func main() {
	startTime := time.Now()
	log.Println("ğŸš€ Go TrendMonitor Starting...")
	log.Println("=" + strings.Repeat("=", 50))
	
	// æ˜¾ç¤ºé…ç½®
	log.Printf("ğŸ“¡ Primary RSSHub: %s", primaryRSSHub)
	log.Printf("ğŸ“¡ Backup mirrors: %v", backupMirrors)
	log.Println("=" + strings.Repeat("=", 50))
	
	// è·å–é¡¹ç›®æ ¹ç›®å½•
	execPath, _ := os.Executable()
	projectRoot := filepath.Dir(filepath.Dir(execPath))
	
	// å¦‚æœæ˜¯ go runï¼Œä½¿ç”¨å½“å‰ç›®å½•
	if strings.Contains(execPath, "go-build") {
		projectRoot, _ = os.Getwd()
		projectRoot = filepath.Dir(projectRoot)
	}
	
	// GitHub Actions ç¯å¢ƒ
	if os.Getenv("GITHUB_WORKSPACE") != "" {
		projectRoot = os.Getenv("GITHUB_WORKSPACE")
	}
	
	// é…ç½®æ–‡ä»¶è·¯å¾„
	rssConfigPath := filepath.Join(projectRoot, "config", "rss_feeds.txt")
	keywordsPath := filepath.Join(projectRoot, "config", "frequency_words.txt")
	historyPath := filepath.Join(projectRoot, "data", "history.json")
	
	// ç¯å¢ƒå˜é‡
	telegramToken := os.Getenv("TELEGRAM_BOT_TOKEN")
	telegramChatID := os.Getenv("TELEGRAM_CHAT_ID")
	
	// é¢„çƒ­ RSSHub
	warmupRSSHub()
	
	// åŠ è½½é…ç½®
	feeds, err := loadRSSConfig(rssConfigPath)
	if err != nil {
		log.Fatalf("âŒ Failed to load RSS config: %v", err)
	}
	log.Printf("ğŸ“‹ Loaded %d RSS feeds", len(feeds))
	
	keywords := loadKeywords(keywordsPath)
	log.Printf("ğŸ”‘ Loaded %d keyword groups", len(keywords))
	
	history := loadHistory(historyPath)
	log.Printf("ğŸ“œ Loaded %d history items", len(history))
	
	// å¹¶å‘æŠ“å–
	var wg sync.WaitGroup
	var mu sync.Mutex
	results := make(map[string][]TrendItem)
	successCount := 0
	failCount := 0
	
	// é™åˆ¶å¹¶å‘æ•°
	semaphore := make(chan struct{}, 5)
	
	for name, rssURL := range feeds {
		wg.Add(1)
		go func(name, url string) {
			defer wg.Done()
			semaphore <- struct{}{}
			defer func() { <-semaphore }()
			
			// éšæœºå»¶è¿Ÿ
			time.Sleep(time.Duration(rand.Intn(1000)) * time.Millisecond)
			
			items, err := fetchSingleRSS(name, url, false)
			if err != nil {
				mu.Lock()
				failCount++
				mu.Unlock()
				log.Printf("âŒ %s failed: %v", name, err)
				return
			}
			
			mu.Lock()
			results[name] = items
			successCount++
			mu.Unlock()
			log.Printf("âœ… %s: %d items", name, len(items))
		}(name, rssURL)
	}
	
	wg.Wait()
	
	log.Printf("ğŸ“Š Fetch complete: %d success, %d failed", successCount, failCount)
	
	// è¿‡æ»¤å’Œå»é‡
	var allItems []TrendItem
	for _, items := range results {
		for _, item := range items {
			// å…³é”®è¯è¿‡æ»¤
			if !matchKeywords(item.Title, keywords) {
				continue
			}
			// å»é‡
			if history[item.URL] {
				continue
			}
			allItems = append(allItems, item)
		}
	}
	
	log.Printf("ğŸ“° %d new items after filtering", len(allItems))
	
	// å‘é€ Telegram
	if telegramToken != "" && telegramChatID != "" && len(allItems) > 0 {
		// åˆ†æ‰¹å‘é€ï¼ˆæ¯æ‰¹ 10 æ¡ï¼‰
		batchSize := 10
		for i := 0; i < len(allItems); i += batchSize {
			end := i + batchSize
			if end > len(allItems) {
				end = len(allItems)
			}
			
			batch := allItems[i:end]
			message := formatMessage(batch)
			
			if err := sendTelegram(telegramToken, telegramChatID, message); err != nil {
				log.Printf("âŒ Telegram send failed: %v", err)
			} else {
				log.Printf("âœ… Sent batch %d-%d", i+1, end)
			}
			
			// é—´éš” 3 ç§’
			if end < len(allItems) {
				time.Sleep(3 * time.Second)
			}
		}
		
		// ä¿å­˜å†å²
		if err := saveHistory(historyPath, allItems, history); err != nil {
			log.Printf("âŒ Failed to save history: %v", err)
		}
	} else if len(allItems) == 0 {
		log.Println("ğŸ“­ No new items to send")
	} else {
		log.Println("âš ï¸ Telegram not configured, dry run mode")
		for i, item := range allItems {
			if i >= 10 {
				log.Printf("... and %d more items", len(allItems)-10)
				break
			}
			log.Printf("  %d. %s", i+1, item.Title)
		}
	}
	
	elapsed := time.Since(startTime)
	log.Printf("â±ï¸ Completed in %v", elapsed)
}

